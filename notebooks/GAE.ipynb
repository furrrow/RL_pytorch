{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generalized Advantage Estimation(GAE): Robust advantage estimation #\n",
    "resources:\n",
    "- https://lilianweng.github.io/posts/2018-02-19-rl-overview/#combining-td-and-mc-learning\n",
    "- DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills (https://arxiv.org/abs/1804.02717)\n",
    "   - only look at the Supplementary Material A\n",
    "- https://github.com/mimoralea/gdrl/blob/master/notebooks/chapter_11/chapter-11.ipynb\n",
    "- https://xlnwel.github.io/blog/reinforcement%20learning/GAE/"
   ],
   "id": "65202b5ced27c690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:36.588039Z",
     "start_time": "2024-04-21T23:16:35.849591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "id": "68288d5dc9ab71bf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:36.977682Z",
     "start_time": "2024-04-21T23:16:36.973496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GAE's optimize model\n",
    "def gae_optimize_model(logpas, rewards, values, gamma, tau):\n",
    "    T = len(rewards)\n",
    "    discounts = np.logspace(0, T, num=T, base=gamma, endpoint=False)\n",
    "    returns = np.array([np.sum(discounts[:T-t] * rewards[t:]) for t in range(T)])\n",
    "\n",
    "    logpas = torch.Tensor(logpas)\n",
    "    # entropies = torch.cat(entropies)\n",
    "    values = torch.Tensor(values)\n",
    "\n",
    "    np_values = values.view(-1).data.numpy()\n",
    "    tau_discounts = np.logspace(0, T-1, num=T-1, base=gamma*tau, endpoint=False)\n",
    "    advs = rewards[:-1] + gamma * np_values[1:] - np_values[:-1]\n",
    "    gaes = np.array([np.sum(tau_discounts[:T-1-t] * advs[t:]) for t in range(T-1)])\n",
    "\n",
    "    values = values[:-1,...]\n",
    "    discounts = torch.FloatTensor(discounts[:-1])\n",
    "    returns = torch.FloatTensor(returns[:-1])\n",
    "    gaes = torch.FloatTensor(gaes)\n",
    "    # # [T-1, T] prior to averaging\n",
    "    policy_loss = -(discounts * gaes.detach() * logpas).mean()\n",
    "    # skipping entropy loss entropy_loss = -entropies.mean()\n",
    "\n",
    "    value_error = returns - values\n",
    "    value_loss = value_error.pow(2).mul(0.5).mean()\n",
    "    return gaes, policy_loss, value_loss"
   ],
   "id": "c7c92b49260d4bc7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:37.386083Z",
     "start_time": "2024-04-21T23:16:37.381523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set dummy inputs and get reference output\n",
    "rewards = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 10])\n",
    "logpas = np.array([.2, .2, .2, .2, .2, .2, .2, .2, .2])\n",
    "values = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "gamma = 0.9\n",
    "tau = 0.5\n",
    "ref_gae, ref_policy_loss, ref_value_loss = gae_optimize_model(logpas, rewards, values, gamma, tau)"
   ],
   "id": "16ac5dfa3df9053c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:37.711989Z",
     "start_time": "2024-04-21T23:16:37.707805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set out the discount vector\n",
    "T = len(rewards)\n",
    "discounts = np.logspace(0, T, num=T, base=gamma, endpoint=False)\n",
    "discounts"
   ],
   "id": "2d5304105f075dad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.9       , 0.81      , 0.729     , 0.6561    ,\n",
       "       0.59049   , 0.531441  , 0.4782969 , 0.43046721, 0.38742049])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:38.118828Z",
     "start_time": "2024-04-21T23:16:38.113826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get discounted returns\n",
    "disc_returns = []\n",
    "for t in range(T):\n",
    "    print(t, discounts[:T-t], rewards[t:])\n",
    "    disc_returns.append(np.sum(discounts[:T-t] * rewards[t:]))\n",
    "disc_returns = np.array(disc_returns)\n",
    "print(\"discounted returns:\")\n",
    "print(disc_returns)"
   ],
   "id": "f2ae110576d360e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.         0.9        0.81       0.729      0.6561     0.59049\n",
      " 0.531441   0.4782969  0.43046721 0.38742049] [ 0  0  0  0  0  0  0  0  0 10]\n",
      "1 [1.         0.9        0.81       0.729      0.6561     0.59049\n",
      " 0.531441   0.4782969  0.43046721] [ 0  0  0  0  0  0  0  0 10]\n",
      "2 [1.        0.9       0.81      0.729     0.6561    0.59049   0.531441\n",
      " 0.4782969] [ 0  0  0  0  0  0  0 10]\n",
      "3 [1.       0.9      0.81     0.729    0.6561   0.59049  0.531441] [ 0  0  0  0  0  0 10]\n",
      "4 [1.      0.9     0.81    0.729   0.6561  0.59049] [ 0  0  0  0  0 10]\n",
      "5 [1.     0.9    0.81   0.729  0.6561] [ 0  0  0  0 10]\n",
      "6 [1.    0.9   0.81  0.729] [ 0  0  0 10]\n",
      "7 [1.   0.9  0.81] [ 0  0 10]\n",
      "8 [1.  0.9] [ 0 10]\n",
      "9 [1.] [10]\n",
      "discounted returns:\n",
      "[ 3.87420489  4.3046721   4.782969    5.31441     5.9049      6.561\n",
      "  7.29        8.1         9.         10.        ]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:38.560266Z",
     "start_time": "2024-04-21T23:16:38.557003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"tau discounts:\n",
    "here, tau=0 means one step return,\n",
    "\"\"\"\n",
    "tau_discounts = np.logspace(0, T-1, num=T-1, base=0*tau, endpoint=False)\n",
    "tau_discounts"
   ],
   "id": "b92893f5338131bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:38.955478Z",
     "start_time": "2024-04-21T23:16:38.951656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"tau discounts:\n",
    "here, tau=1 means infinite return,\n",
    "and tau serves to adjust between the two extremes\n",
    "\"\"\"\n",
    "tau_discounts = np.logspace(0, T-1, num=T-1, base=1*tau, endpoint=False)\n",
    "tau_discounts"
   ],
   "id": "55414a0bbc90bf91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.5       , 0.25      , 0.125     , 0.0625    ,\n",
       "       0.03125   , 0.015625  , 0.0078125 , 0.00390625])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:39.285911Z",
     "start_time": "2024-04-21T23:16:39.283026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using the saved tau value from above from here\n",
    "tau_discounts = np.logspace(0, T-1, num=T-1, base=gamma*tau, endpoint=False)\n",
    "print(\"tau discounts\", tau_discounts)"
   ],
   "id": "8d5f544ce9a96002",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau discounts [1.         0.45       0.2025     0.091125   0.04100625 0.01845281\n",
      " 0.00830377 0.00373669 0.00168151]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:39.690825Z",
     "start_time": "2024-04-21T23:16:39.688066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the advantage calculation:\n",
    "print(rewards[:-1])\n",
    "print(values[1:], gamma * values[1:])\n",
    "print(values[:-1])"
   ],
   "id": "295000fbe36c6618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1] [0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9]\n",
      "[1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:40.078291Z",
     "start_time": "2024-04-21T23:16:40.075543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GAEs are but discounted sum of td errors...\n",
    "# td errors: R+t + gamma*value_t+1 - value_t for t=0 to T\n",
    "advs = rewards[:-1] + gamma * values[1:] - values[:-1]\n",
    "print(\"advantages\", advs)"
   ],
   "id": "2c4df8c729afd364",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advantages [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:40.473447Z",
     "start_time": "2024-04-21T23:16:40.468528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get discounted returns\n",
    "gaes = []\n",
    "for t in range(T-1):\n",
    "    print(t, tau_discounts[:T-1-t], advs[t:])\n",
    "    gaes.append(np.sum(tau_discounts[:T-1-t] * advs[t:]))\n",
    "gaes = np.array(gaes)\n",
    "print(\"gaes returns:\")\n",
    "print(gaes)"
   ],
   "id": "1edb4d5939b1b7e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.         0.45       0.2025     0.091125   0.04100625 0.01845281\n",
      " 0.00830377 0.00373669 0.00168151] [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n",
      "1 [1.         0.45       0.2025     0.091125   0.04100625 0.01845281\n",
      " 0.00830377 0.00373669] [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n",
      "2 [1.         0.45       0.2025     0.091125   0.04100625 0.01845281\n",
      " 0.00830377] [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n",
      "3 [1.         0.45       0.2025     0.091125   0.04100625 0.01845281] [-0.1 -0.1 -0.1 -0.1 -0.1 -0.1]\n",
      "4 [1.         0.45       0.2025     0.091125   0.04100625] [-0.1 -0.1 -0.1 -0.1 -0.1]\n",
      "5 [1.       0.45     0.2025   0.091125] [-0.1 -0.1 -0.1 -0.1]\n",
      "6 [1.     0.45   0.2025] [-0.1 -0.1 -0.1]\n",
      "7 [1.   0.45] [-0.1 -0.1]\n",
      "8 [1.] [-0.1]\n",
      "gaes returns:\n",
      "[-0.1816806  -0.18151245 -0.18113878 -0.18030841 -0.17846312 -0.1743625\n",
      " -0.16525    -0.145      -0.1       ]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:40.934040Z",
     "start_time": "2024-04-21T23:16:40.931180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the gae and reference gae should match\n",
    "print(gaes)\n",
    "print(np.array(ref_gae).squeeze())"
   ],
   "id": "93dacc4b4c69144c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1816806  -0.18151245 -0.18113878 -0.18030841 -0.17846312 -0.1743625\n",
      " -0.16525    -0.145      -0.1       ]\n",
      "[-0.18168065 -0.18151249 -0.18113883 -0.18030845 -0.17846316 -0.17436254\n",
      " -0.16525003 -0.14500004 -0.10000002]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:41.429382Z",
     "start_time": "2024-04-21T23:16:41.425653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy_loss = -np.mean(discounts[:-1] * gaes * logpas)\n",
    "print(policy_loss)\n",
    "print(ref_policy_loss)"
   ],
   "id": "cc741fbdd32580b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02318840929956597\n",
      "tensor(0.0232)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T23:16:41.880568Z",
     "start_time": "2024-04-21T23:16:41.876560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "my_loss = criterion(torch.Tensor(disc_returns[:-1]), torch.Tensor(values[:-1]))\n",
    "# miguel uses an extra 0.5 compared to regular MSE loss\n",
    "print(my_loss/2)\n",
    "print(ref_value_loss)"
   ],
   "id": "d01fd9da837c83b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.5035)\n",
      "tensor(14.5035)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "142d05a8fcc32d74"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
