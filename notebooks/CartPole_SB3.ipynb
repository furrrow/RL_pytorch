{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/miniconda3/envs/torch/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:20.39 +/- 4.17\n"
     ]
    }
   ],
   "source": [
    "# Use a separate environement for evaluation\n",
    "eval_env = gym.make('CartPole-v1')\n",
    "model = DQN(\"MlpPolicy\", eval_env, verbose=0)\n",
    "\n",
    "# Random Agent, before training\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/miniconda3/envs/torch/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:67.39 +/- 10.06\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=0)\n",
    "model.learn(total_timesteps=10000, log_interval=4)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "model.save(\"dqn_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m action, _states \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(obs, deterministic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m obs, reward, done, info \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[0;32m----> 7\u001B[0m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m      9\u001B[0m     obs \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mreset()\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/gym/core.py:295\u001B[0m, in \u001B[0;36mWrapper.render\u001B[0;34m(self, mode, **kwargs)\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 295\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:229\u001B[0m, in \u001B[0;36mCartPoleEnv.render\u001B[0;34m(self, mode)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcarttrans\u001B[38;5;241m.\u001B[39mset_translation(cartx, carty)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpoletrans\u001B[38;5;241m.\u001B[39mset_rotation(\u001B[38;5;241m-\u001B[39mx[\u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m--> 229\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mviewer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreturn_rgb_array\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrgb_array\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/gym/envs/classic_control/rendering.py:145\u001B[0m, in \u001B[0;36mViewer.render\u001B[0;34m(self, return_rgb_array)\u001B[0m\n\u001B[1;32m    143\u001B[0m     arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mreshape(buffer\u001B[38;5;241m.\u001B[39mheight, buffer\u001B[38;5;241m.\u001B[39mwidth, \u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m    144\u001B[0m     arr \u001B[38;5;241m=\u001B[39m arr[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :, \u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m3\u001B[39m]\n\u001B[0;32m--> 145\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39monetime_geoms \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr \u001B[38;5;28;01mif\u001B[39;00m return_rgb_array \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39misopen\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pyglet/window/xlib/__init__.py:531\u001B[0m, in \u001B[0;36mXlibWindow.flip\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    529\u001B[0m \u001B[38;5;66;03m# TODO canvas.flip?\u001B[39;00m\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext:\n\u001B[0;32m--> 531\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sync_resize()\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/pyglet/gl/xlib.py:376\u001B[0m, in \u001B[0;36mXlibContext13.flip\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vsync:\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_vsync()\n\u001B[0;32m--> 376\u001B[0m \u001B[43mglx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mglXSwapBuffers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_display\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mglx_window\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"dqn_cartpole\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}